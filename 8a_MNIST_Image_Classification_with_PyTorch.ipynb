{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5409fda3",
   "metadata": {},
   "source": [
    "# MNIST Image Classification with a Neural Network (PyTorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ea5c4c",
   "metadata": {},
   "source": [
    "\n",
    "This notebook demonstrates the power of **PyTorch** and neural networks for image classification on the **MNIST dataset**. \n",
    "We will build a simple neural network to classify handwritten digits (0-9) from MNIST images. This example showcases \n",
    "how neural networks can learn patterns from raw image data and make accurate predictions.\n",
    "\n",
    "The process involves:\n",
    "1. Loading the MNIST dataset.\n",
    "2. Defining a neural network model.\n",
    "3. Training the model on the dataset.\n",
    "4. Evaluating the model's accuracy.\n",
    "5. Visualizing predictions to see the network's performance.\n",
    "\n",
    "Let's get started!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3865a6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define transformations for the dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Load the MNIST training and test datasets\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92e15a2",
   "metadata": {},
   "source": [
    "## Define the Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f22a9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(28 * 28, 128)\n",
    "        self.layer2 = nn.Linear(128, 64)\n",
    "        self.layer3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # Flatten the image\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the neural network, loss function, and optimizer\n",
    "model = SimpleNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff0b75d",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5323dc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 1.0904985992257783\n",
      "Epoch 2/5, Loss: 0.3949735839324974\n",
      "Epoch 3/5, Loss: 0.3286885799709032\n",
      "Epoch 4/5, Loss: 0.2949009775591176\n",
      "Epoch 5/5, Loss: 0.26941936072319556\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training loop\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in trainloader:\n",
    "        optimizer.zero_grad()               # Reset gradients\n",
    "        outputs = model(images)             # Forward pass\n",
    "        loss = criterion(outputs, labels)   # Calculate loss\n",
    "        loss.backward()                     # Backpropagate\n",
    "        optimizer.step()                    # Update weights\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(trainloader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8e3285",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76d7e34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 92.55%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model on the test dataset\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  # No need to calculate gradients during evaluation\n",
    "    for images, labels in testloader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae3799f",
   "metadata": {},
   "source": [
    "## Visualize Some Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d58da07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to visualize predictions\n",
    "def visualize_predictions():\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = next(dataiter)  # Use next(dataiter) instead of dataiter.next()\n",
    "    \n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    # Display images and predictions\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(10, 2))\n",
    "    for i in range(5):\n",
    "        axes[i].imshow(images[i].reshape(28, 28), cmap='gray')\n",
    "        axes[i].set_title(f'Pred: {predicted[i].item()}')\n",
    "        axes[i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize predictions\n",
    "visualize_predictions()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3411340",
   "metadata": {},
   "source": [
    "\n",
    "### Summary\n",
    "\n",
    "In this notebook, we built a simple neural network with PyTorch to classify images from the MNIST dataset. \n",
    "We trained the model, evaluated its accuracy, and visualized some predictions. This example shows the power \n",
    "of neural networks in recognizing patterns in image data and highlights PyTorch's ease of use for building \n",
    "and training models.\n",
    "\n",
    "Key takeaways:\n",
    "- **Neural networks** can recognize patterns in complex data like images without manual feature engineering.\n",
    "- **PyTorch** simplifies defining and training neural networks, allowing experimentation with different architectures.\n",
    "- **Visualization** helps in understanding the modelâ€™s predictions and assessing its performance.\n",
    "\n",
    "This is just a starting point; you can experiment further by adding more layers or using different architectures to improve accuracy.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
